{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get data\n",
    "\n",
    "from data_utils import load_fashion_mnist\n",
    "\n",
    "trX, teX, _, _ = load_fashion_mnist(onehot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f81db6185c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#view data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(trX[0].reshape(28,28), cmap=plt.get_cmap('gray')) #need cmap thing or else is weird colour\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert from numpy arrays to torch tensors\n",
    "\n",
    "trX = torch.from_numpy(trX).float()\n",
    "teX = torch.from_numpy(teX).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # to find the size (width x height) of a square image leaving a conv layer, the equation is:\n",
    "        # Wo = ((Wiâˆ’F+2*P)/S)+1, \n",
    "        # Wo is the width of the image output\n",
    "        # Wi is the width of the image going in\n",
    "        # F is the filter width (aka 'kernel size')\n",
    "        # P is the padding\n",
    "        # S is the stride\n",
    "        \n",
    "        self.enc_conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=3, padding=1)\n",
    "        # Wo = ((28-3+2*1)/3)+1 = 10\n",
    "        self.enc_conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=2, padding=1)\n",
    "        # Wo = ((5-3+2*1)/2)+1 = 3\n",
    "        \n",
    "        # to find the size (width x height) of a square image leaving a conv-transpose layer, the equation is:\n",
    "        # Wo = (Wi-1)*S-2*P+F\n",
    "\n",
    "        self.dec_conv1 = nn.ConvTranspose2d(in_channels=8, out_channels=16, kernel_size=3, stride=2)\n",
    "        # Wo = (2-1)*2-2*0+3 = 5\n",
    "        self.dec_conv2 = nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=5, stride=3, padding=1)\n",
    "        # Wo = (5-1)*3-2*1+5 = 15\n",
    "        self.dec_conv3 = nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=2, stride=2, padding=1)\n",
    "        # Wo = (15-1)*2-2*1+2 = 28\n",
    "        \n",
    "        #for pooling layers\n",
    "        # Wo = floor((Wi+2*P-(F-1)-1)/S+1) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = [32, 1, 28, 28]\n",
    "        x = self.enc_conv1(x)\n",
    "        #x = [32, 16, 10, 10]\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        #x = [32, 16, 5, 5]\n",
    "        x = self.enc_conv2(x)\n",
    "        #x = [32, 8, 3, 3]\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=1)\n",
    "        #x = [32, 8, 2, 2]\n",
    "        encoded = x\n",
    "        x = self.dec_conv1(x)\n",
    "        #x = [32, 16, 5, 5]\n",
    "        x = F.relu(x)\n",
    "        x = self.dec_conv2(x)\n",
    "        #x = [32, 8, 15, 15]\n",
    "        x = F.relu(x)\n",
    "        x = self.dec_conv3(x)\n",
    "        #x = [32, 1, 28, 28]\n",
    "        decoded = F.sigmoid(x)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of AutoEncoder class\n",
    "\n",
    "autoencoder = AutoEncoder(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define some parameters\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for plotting\n",
    "\n",
    "plot_loss = []\n",
    "plot_correct = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss and optimizer\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training function\n",
    "\n",
    "def train(model, criterion, optimizer, x, y):\n",
    "    x = Variable(x, requires_grad=False)\n",
    "    y = Variable(y, requires_grad=False)\n",
    "    \n",
    "    # Reset gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward\n",
    "    _, decoded = model.forward(x)\n",
    "    loss = criterion(decoded, y)\n",
    "\n",
    "    # Backward\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, loss = 0.042735\n",
      "Epoch 02, loss = 0.025688\n",
      "Epoch 03, loss = 0.022542\n",
      "Epoch 04, loss = 0.021145\n",
      "Epoch 05, loss = 0.020286\n",
      "Epoch 06, loss = 0.019674\n"
     ]
    }
   ],
   "source": [
    "#run the training\n",
    "\n",
    "num_examples = trX.shape[0]\n",
    "num_batches = num_examples // batch_size\n",
    "\n",
    "#need to reshape to 4D to feed into convolutional neural net\n",
    "trX = trX.view(-1, 1, 28, 28) #from [60000,784] to [60000, 1, 28, 28], the '1' is the number of colour channels\n",
    "teX = teX.view(-1, 1, 28, 28)\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    loss = 0.\n",
    "    for k in range(num_batches):\n",
    "        start, end = k * batch_size, (k + 1) * batch_size\n",
    "        loss += train(autoencoder, criterion, optimizer, trX[start:end], trX[start:end])\n",
    "    plot_loss.append(loss/num_batches)\n",
    "    print(\"Epoch %02d, loss = %f\" % (e, loss / num_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(plot_loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Avg. Loss per Epoch (on Training Set)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teX = Variable(teX, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, decoded = autoencoder.forward(teX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view some\n",
    "\n",
    "num_display = 5\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(num_display):\n",
    "    fig.add_subplot(1,num_display,i+1)\n",
    "    plt.imshow(np.reshape(teX[i+5].data.numpy(), (28,28)), cmap=plt.get_cmap('gray'))\n",
    "    \n",
    "fig = plt.figure()\n",
    "\n",
    "for i in range(num_display):\n",
    "    fig.add_subplot(1,num_display,i+1)\n",
    "    plt.imshow(np.reshape(decoded[i+5].data.numpy(), (28,28)), cmap=plt.get_cmap('gray'))\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
